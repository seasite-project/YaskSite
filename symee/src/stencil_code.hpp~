// Automatically generated code; do not edit.

////// YASK implementation of the 'ys_RHS_LC_emb_jil_yasksite_Heat2D' stencil //////

/*
Identified stencil equation-groups:
 Equation group 'stencil_1' updates grid 'k_0' with dim = 4.
 Equation group 'stencil_1' updates grid 'k_1' with dim = 4.
 Equation group 'stencil_1' reads grid 'h_inv' with dim = 0.
 Equation group 'stencil_1' reads grid 'k_2' with dim = 4.
 Equation group 'stencil_1' reads grid 'k_0' with dim = 4.
 Equation group 'stencil_1' reads grid 'k_1' with dim = 4.
 Equation group 'stencil_2' updates grid 'k_2' with dim = 4.
 Equation group 'stencil_2' reads grid 'h_inv' with dim = 0.
 Equation group 'stencil_2' reads grid 'k_2' with dim = 4.
 Equation group 'stencil_0' updates grid 'data' with dim = 4.
 Equation group 'stencil_0' reads grid 'k_2' with dim = 4.
 Equation group 'stencil_0' reads grid 'k_1' with dim = 4.
 Equation group 'stencil_0' reads grid 'k_0' with dim = 4.
 Equation group 'stencil_0' reads grid 'data' with dim = 4.
 Equation group 'stencil_0' reads grid 'dt' with dim = 0.
*/

namespace yask {

 ////// Stencil-specific data //////
struct StencilContext_ys_RHS_LC_emb_jil_yasksite_Heat2D_data : public StencilContext {

 ///// Grid(s).

 // The 4D 'data' grid, which is updated by one or more equations.
 static const idx_t data_alloc_t = 1; // total allocation required in 't' dimension.
 Grid_TXYZ<data_alloc_t>* data;
 const idx_t data_halo_x = 0; // halo allocation required in 'x' dimension.
 const idx_t data_halo_y = 0; // halo allocation required in 'y' dimension.
 const idx_t data_halo_z = 0; // halo allocation required in 'z' dimension.

 // The 4D 'F' grid, which is not updated by any equation (read-only).
 static const idx_t F_alloc_t = 1; // total allocation required in 't' dimension.
 Grid_TXYZ<F_alloc_t>* F;
 const idx_t F_halo_x = 0; // halo allocation required in 'x' dimension.
 const idx_t F_halo_y = 0; // halo allocation required in 'y' dimension.
 const idx_t F_halo_z = 0; // halo allocation required in 'z' dimension.

 // The 4D 'k_0' grid, which is updated by one or more equations.
 static const idx_t k_0_alloc_t = 1; // total allocation required in 't' dimension.
 Grid_TXYZ<k_0_alloc_t>* k_0;
 const idx_t k_0_halo_x = 0; // halo allocation required in 'x' dimension.
 const idx_t k_0_halo_y = 1; // halo allocation required in 'y' dimension.
 const idx_t k_0_halo_z = 1; // halo allocation required in 'z' dimension.

 // The 4D 'k_1' grid, which is updated by one or more equations.
 static const idx_t k_1_alloc_t = 1; // total allocation required in 't' dimension.
 Grid_TXYZ<k_1_alloc_t>* k_1;
 const idx_t k_1_halo_x = 0; // halo allocation required in 'x' dimension.
 const idx_t k_1_halo_y = 1; // halo allocation required in 'y' dimension.
 const idx_t k_1_halo_z = 1; // halo allocation required in 'z' dimension.

 // The 4D 'k_2' grid, which is updated by one or more equations.
 static const idx_t k_2_alloc_t = 1; // total allocation required in 't' dimension.
 Grid_TXYZ<k_2_alloc_t>* k_2;
 const idx_t k_2_halo_x = 0; // halo allocation required in 'x' dimension.
 const idx_t k_2_halo_y = 1; // halo allocation required in 'y' dimension.
 const idx_t k_2_halo_z = 1; // halo allocation required in 'z' dimension.

 // Max halos across all grids.
 const idx_t max_halo_x = 0;
 const idx_t max_halo_y = 1;
 const idx_t max_halo_z = 1;

 ///// Parameter(s).

 // The 0D 'h_inv' parameter.
 GenericGrid0d<real_t>* h_inv;

 // The 0D 'dt' parameter.
 GenericGrid0d<real_t>* dt;

 // Constructor.
 StencilContext_ys_RHS_LC_emb_jil_yasksite_Heat2D_data(StencilSettings& settings) : StencilContext(settings) {
  name = "ys_RHS_LC_emb_jil_yasksite_Heat2D";

 // Create grids and parameters.

  // Init grid 'data'.
 data = new Grid_TXYZ<data_alloc_t>("data");
 gridPtrs.push_back(data);
 gridMap["data"] = data;
 outputGridPtrs.push_back(data);
 outputGridMap["data"] = data;
 data->set_halo_x(data_halo_x);
 data->set_halo_y(data_halo_y);
 data->set_halo_z(data_halo_z);

  // Init grid 'F'.
 F = new Grid_TXYZ<F_alloc_t>("F");
 gridPtrs.push_back(F);
 gridMap["F"] = F;
 F->set_halo_x(F_halo_x);
 F->set_halo_y(F_halo_y);
 F->set_halo_z(F_halo_z);

  // Init grid 'k_0'.
 k_0 = new Grid_TXYZ<k_0_alloc_t>("k_0");
 gridPtrs.push_back(k_0);
 gridMap["k_0"] = k_0;
 outputGridPtrs.push_back(k_0);
 outputGridMap["k_0"] = k_0;
 k_0->set_halo_x(k_0_halo_x);
 k_0->set_halo_y(k_0_halo_y);
 k_0->set_halo_z(k_0_halo_z);

  // Init grid 'k_1'.
 k_1 = new Grid_TXYZ<k_1_alloc_t>("k_1");
 gridPtrs.push_back(k_1);
 gridMap["k_1"] = k_1;
 outputGridPtrs.push_back(k_1);
 outputGridMap["k_1"] = k_1;
 k_1->set_halo_x(k_1_halo_x);
 k_1->set_halo_y(k_1_halo_y);
 k_1->set_halo_z(k_1_halo_z);

  // Init grid 'k_2'.
 k_2 = new Grid_TXYZ<k_2_alloc_t>("k_2");
 gridPtrs.push_back(k_2);
 gridMap["k_2"] = k_2;
 outputGridPtrs.push_back(k_2);
 outputGridMap["k_2"] = k_2;
 k_2->set_halo_x(k_2_halo_x);
 k_2->set_halo_y(k_2_halo_y);
 k_2->set_halo_z(k_2_halo_z);

  // Init parameter 'h_inv'.
 h_inv = new GenericGrid0d<real_t>();
 paramPtrs.push_back(h_inv);
 paramMap["h_inv"] = h_inv;

  // Init parameter 'dt'.
 dt = new GenericGrid0d<real_t>();
 paramPtrs.push_back(dt);
 paramMap["dt"] = dt;

  // Rounded halo sizes.
  hx = ROUND_UP(max_halo_x, VLEN_X);
  hy = ROUND_UP(max_halo_y, VLEN_Y);
  hz = ROUND_UP(max_halo_z, VLEN_Z);
 }
}; // StencilContext_ys_RHS_LC_emb_jil_yasksite_Heat2D_data

 ////// Stencil equation-group 'stencil_1' w/no condition //////

 class EqGroup_stencil_1 : public EqGroupBase {
 protected:
 StencilContext_ys_RHS_LC_emb_jil_yasksite_Heat2D_data* _context = 0;
 public:

 // 23 FP operation(s) per point:
 // k_0(t, x, y, z) EQUALS ((0 * k_2(t, x, y, z)) + (((1 * k_0(t, x, y+1, z)) + (1 * k_0(t, x, y-1, z)) + (1 * k_0(t, x, y, z+1)) + (1 * k_0(t, x, y, z-1)) + (-4 * k_0(t, x, y, z))) * h_inv)).
 // k_1(t, x, y, z) EQUALS ((0 * k_2(t, x, y, z)) + (((1 * k_1(t, x, y+1, z)) + (1 * k_1(t, x, y-1, z)) + (1 * k_1(t, x, y, z+1)) + (1 * k_1(t, x, y, z-1)) + (-4 * k_1(t, x, y, z))) * h_inv)).
 EqGroup_stencil_1(StencilContext_ys_RHS_LC_emb_jil_yasksite_Heat2D_data* context) :
 EqGroupBase(context),
 _context(context) {
 _name = "stencil_1";
 _scalar_fp_ops = 23;
 _scalar_points_read = 11;
 _scalar_points_written = 2;

 // The following grids are written by EqGroup_stencil_1
  outputGridPtrs.push_back(_context->k_0);
  outputGridPtrs.push_back(_context->k_1);

 // The following grids are read by EqGroup_stencil_1
  inputGridPtrs.push_back(_context->k_2);
  inputGridPtrs.push_back(_context->k_0);
  inputGridPtrs.push_back(_context->k_1);
 } // Ctor.

 // Determine whether EqGroup_stencil_1 is valid at the given indices. Return true if indices are within the valid sub-domain or false otherwise.
 virtual bool is_in_valid_domain(idx_t t, idx_t x, idx_t y, idx_t z) {
 return (x>=FIRST_INDEX(x)) && (x<=LAST_INDEX(x)) && (y>=FIRST_INDEX(y)) && (y<=LAST_INDEX(y)) && (z>=FIRST_INDEX(z)) && (z<=LAST_INDEX(z)); // full domain.
 }

 // Calculate one scalar result relative to indices t, x, y, z.
 virtual void calc_scalar(idx_t t, idx_t x, idx_t y, idx_t z) {

 // temp1 = 0 * k_2(t, x, y, z).
 real_t temp1 = 0.00000000000000000e+00 * _context->k_2->readElem(t, x, y, z, __LINE__);

 // temp2 = 1 * k_0(t, x, y+1, z).
 real_t temp2 = 1.00000000000000000e+00 * _context->k_0->readElem(t, x, y+1, z, __LINE__);

 // temp3 = 1 * k_0(t, x, y-1, z).
 real_t temp3 = 1.00000000000000000e+00 * _context->k_0->readElem(t, x, y-1, z, __LINE__);

 // temp4 = (1 * k_0(t, x, y+1, z)) + (1 * k_0(t, x, y-1, z)).
 real_t temp4 = temp2 + temp3;

 // temp5 = 1 * k_0(t, x, y, z+1).
 real_t temp5 = 1.00000000000000000e+00 * _context->k_0->readElem(t, x, y, z+1, __LINE__);

 // temp6 = (1 * k_0(t, x, y+1, z)) + (1 * k_0(t, x, y-1, z)) + (1 * k_0(t, x, y, z+1)).
 real_t temp6 = temp4 + temp5;

 // temp7 = 1 * k_0(t, x, y, z-1).
 real_t temp7 = 1.00000000000000000e+00 * _context->k_0->readElem(t, x, y, z-1, __LINE__);

 // temp8 = (1 * k_0(t, x, y+1, z)) + (1 * k_0(t, x, y-1, z)) + (1 * k_0(t, x, y, z+1)) + (1 * k_0(t, x, y, z-1)).
 real_t temp8 = temp6 + temp7;

 // temp9 = -4 * k_0(t, x, y, z).
 real_t temp9 = -4.00000000000000000e+00 * _context->k_0->readElem(t, x, y, z, __LINE__);

 // temp10 = (1 * k_0(t, x, y+1, z)) + (1 * k_0(t, x, y-1, z)) + (1 * k_0(t, x, y, z+1)) + (1 * k_0(t, x, y, z-1)) + (-4 * k_0(t, x, y, z)).
 real_t temp10 = temp8 + temp9;

 // temp11 = ((1 * k_0(t, x, y+1, z)) + (1 * k_0(t, x, y-1, z)) + (1 * k_0(t, x, y, z+1)) + (1 * k_0(t, x, y, z-1)) + (-4 * k_0(t, x, y, z))) * h_inv().
 real_t temp11 = temp10 * (*_context->h_inv)();

 // temp12 = (0 * k_2(t, x, y, z)) + (((1 * k_0(t, x, y+1, z)) + (1 * k_0(t, x, y-1, z)) + (1 * k_0(t, x, y, z+1)) + (1 * k_0(t, x, y, z-1)) + (-4 * k_0(t, x, y, z))) * h_inv).
 real_t temp12 = temp1 + temp11;

 // temp13 = ((0 * k_2(t, x, y, z)) + (((1 * k_0(t, x, y+1, z)) + (1 * k_0(t, x, y-1, z)) + (1 * k_0(t, x, y, z+1)) + (1 * k_0(t, x, y, z-1)) + (-4 * k_0(t, x, y, z))) * h_inv)).
 real_t temp13 = temp12;

 // Define value at k_0(t, x, y, z).
 _context->k_0->writeElem(temp13, t, x, y, z, __LINE__);

 // temp14 = 1 * k_1(t, x, y+1, z).
 real_t temp14 = 1.00000000000000000e+00 * _context->k_1->readElem(t, x, y+1, z, __LINE__);

 // temp15 = 1 * k_1(t, x, y-1, z).
 real_t temp15 = 1.00000000000000000e+00 * _context->k_1->readElem(t, x, y-1, z, __LINE__);

 // temp16 = (1 * k_1(t, x, y+1, z)) + (1 * k_1(t, x, y-1, z)).
 real_t temp16 = temp14 + temp15;

 // temp17 = 1 * k_1(t, x, y, z+1).
 real_t temp17 = 1.00000000000000000e+00 * _context->k_1->readElem(t, x, y, z+1, __LINE__);

 // temp18 = (1 * k_1(t, x, y+1, z)) + (1 * k_1(t, x, y-1, z)) + (1 * k_1(t, x, y, z+1)).
 real_t temp18 = temp16 + temp17;

 // temp19 = 1 * k_1(t, x, y, z-1).
 real_t temp19 = 1.00000000000000000e+00 * _context->k_1->readElem(t, x, y, z-1, __LINE__);

 // temp20 = (1 * k_1(t, x, y+1, z)) + (1 * k_1(t, x, y-1, z)) + (1 * k_1(t, x, y, z+1)) + (1 * k_1(t, x, y, z-1)).
 real_t temp20 = temp18 + temp19;

 // temp21 = -4 * k_1(t, x, y, z).
 real_t temp21 = -4.00000000000000000e+00 * _context->k_1->readElem(t, x, y, z, __LINE__);

 // temp22 = (1 * k_1(t, x, y+1, z)) + (1 * k_1(t, x, y-1, z)) + (1 * k_1(t, x, y, z+1)) + (1 * k_1(t, x, y, z-1)) + (-4 * k_1(t, x, y, z)).
 real_t temp22 = temp20 + temp21;

 // temp23 = ((1 * k_1(t, x, y+1, z)) + (1 * k_1(t, x, y-1, z)) + (1 * k_1(t, x, y, z+1)) + (1 * k_1(t, x, y, z-1)) + (-4 * k_1(t, x, y, z))) * h_inv().
 real_t temp23 = temp22 * (*_context->h_inv)();

 // temp24 = (0 * k_2(t, x, y, z)) + (((1 * k_1(t, x, y+1, z)) + (1 * k_1(t, x, y-1, z)) + (1 * k_1(t, x, y, z+1)) + (1 * k_1(t, x, y, z-1)) + (-4 * k_1(t, x, y, z))) * h_inv).
 real_t temp24 = temp1 + temp23;

 // temp25 = ((0 * k_2(t, x, y, z)) + (((1 * k_1(t, x, y+1, z)) + (1 * k_1(t, x, y-1, z)) + (1 * k_1(t, x, y, z+1)) + (1 * k_1(t, x, y, z-1)) + (-4 * k_1(t, x, y, z))) * h_inv)).
 real_t temp25 = temp24;

 // Define value at k_1(t, x, y, z).
 _context->k_1->writeElem(temp25, t, x, y, z, __LINE__);
} // calc_scalar.

 // Calculate 4 result(s) relative to indices t, x, y, z in a 'x=1 * y=1 * z=4' cluster containing 1 'x=1 * y=1 * z=4' vector(s).
 // Indices must be normalized, i.e., already divided by VLEN_*.
 // SIMD calculations use 11 vector block(s) created from 11 aligned vector-block(s).
 // There are approximately 92 FP operation(s) per invocation.
 inline void calc_cluster(idx_t tv, idx_t xv, idx_t yv, idx_t zv) {

 // Element (un-normalized) indices.
 idx_t t = tv;
 idx_t x = xv * VLEN_X;
 idx_t y = yv * VLEN_Y;
 idx_t z = zv * VLEN_Z;

 // Read aligned vector block from k_2 at t, x, y, z.
 real_vec_t temp_vec1 =  _context->k_2->readVecNorm(tv, xv, yv, zv, __LINE__);

 // Read aligned vector block from k_0 at t, x, y+1, z.
 real_vec_t temp_vec2 =  _context->k_0->readVecNorm(tv, xv, yv + (1 / VLEN_Y), zv, __LINE__);

 // Read aligned vector block from k_0 at t, x, y-1, z.
 real_vec_t temp_vec3 =  _context->k_0->readVecNorm(tv, xv, yv - (1 / VLEN_Y), zv, __LINE__);

 // Read aligned vector block from k_0 at t, x, y, z.
 real_vec_t temp_vec4 =  _context->k_0->readVecNorm(tv, xv, yv, zv, __LINE__);

 // Read aligned vector block from k_0 at t, x, y, z+4.
 real_vec_t temp_vec5 =  _context->k_0->readVecNorm(tv, xv, yv, zv + (4 / VLEN_Z), __LINE__);

 // Construct unaligned vector block from k_0 at t, x, y, z+1.
 real_vec_t temp_vec6;
 // temp_vec6[0] = temp_vec4[1];  // for t, x, y, z+1;
 // temp_vec6[1] = temp_vec4[2];  // for t, x, y, z+2;
 // temp_vec6[2] = temp_vec4[3];  // for t, x, y, z+3;
 // temp_vec6[3] = temp_vec5[0];  // for t, x, y, z+4;
 // Get 1 element(s) from temp_vec5 and 3 from temp_vec4.
 real_vec_align<1>(temp_vec6, temp_vec5, temp_vec4);

 // Read aligned vector block from k_0 at t, x, y, z-4.
 real_vec_t temp_vec7 =  _context->k_0->readVecNorm(tv, xv, yv, zv - (4 / VLEN_Z), __LINE__);

 // Construct unaligned vector block from k_0 at t, x, y, z-1.
 real_vec_t temp_vec8;
 // temp_vec8[0] = temp_vec7[3];  // for t, x, y, z-1;
 // temp_vec8[1] = temp_vec4[0];  // for t, x, y, z;
 // temp_vec8[2] = temp_vec4[1];  // for t, x, y, z+1;
 // temp_vec8[3] = temp_vec4[2];  // for t, x, y, z+2;
 // Get 3 element(s) from temp_vec4 and 1 from temp_vec7.
 real_vec_align<3>(temp_vec8, temp_vec4, temp_vec7);

 // temp_vec9 = 0 * k_2(t, x, y, z).
 real_vec_t temp_vec9 = 0.00000000000000000e+00 * temp_vec1;

 // temp_vec10 = 1 * k_0(t, x, y+1, z).
 real_vec_t temp_vec10 = 1.00000000000000000e+00 * temp_vec2;

 // temp_vec11 = 1 * k_0(t, x, y-1, z).
 real_vec_t temp_vec11 = 1.00000000000000000e+00 * temp_vec3;

 // temp_vec12 = (1 * k_0(t, x, y+1, z)) + (1 * k_0(t, x, y-1, z)).
 real_vec_t temp_vec12 = temp_vec10 + temp_vec11;

 // temp_vec13 = 1 * k_0(t, x, y, z+1).
 real_vec_t temp_vec13 = 1.00000000000000000e+00 * temp_vec6;

 // temp_vec14 = (1 * k_0(t, x, y+1, z)) + (1 * k_0(t, x, y-1, z)) + (1 * k_0(t, x, y, z+1)).
 real_vec_t temp_vec14 = temp_vec12 + temp_vec13;

 // temp_vec15 = 1 * k_0(t, x, y, z-1).
 real_vec_t temp_vec15 = 1.00000000000000000e+00 * temp_vec8;

 // temp_vec16 = (1 * k_0(t, x, y+1, z)) + (1 * k_0(t, x, y-1, z)) + (1 * k_0(t, x, y, z+1)) + (1 * k_0(t, x, y, z-1)).
 real_vec_t temp_vec16 = temp_vec14 + temp_vec15;

 // temp_vec17 = -4 * k_0(t, x, y, z).
 real_vec_t temp_vec17 = -4.00000000000000000e+00 * temp_vec4;

 // temp_vec18 = (1 * k_0(t, x, y+1, z)) + (1 * k_0(t, x, y-1, z)) + (1 * k_0(t, x, y, z+1)) + (1 * k_0(t, x, y, z-1)) + (-4 * k_0(t, x, y, z)).
 real_vec_t temp_vec18 = temp_vec16 + temp_vec17;

 // temp_vec19 = ((1 * k_0(t, x, y+1, z)) + (1 * k_0(t, x, y-1, z)) + (1 * k_0(t, x, y, z+1)) + (1 * k_0(t, x, y, z-1)) + (-4 * k_0(t, x, y, z))) * h_inv().
 real_vec_t temp_vec19 = temp_vec18 * (*_context->h_inv)();

 // temp_vec20 = (0 * k_2(t, x, y, z)) + (((1 * k_0(t, x, y+1, z)) + (1 * k_0(t, x, y-1, z)) + (1 * k_0(t, x, y, z+1)) + (1 * k_0(t, x, y, z-1)) + (-4 * k_0(t, x, y, z))) * h_inv).
 real_vec_t temp_vec20 = temp_vec9 + temp_vec19;

 // temp_vec21 = ((0 * k_2(t, x, y, z)) + (((1 * k_0(t, x, y+1, z)) + (1 * k_0(t, x, y-1, z)) + (1 * k_0(t, x, y, z+1)) + (1 * k_0(t, x, y, z-1)) + (-4 * k_0(t, x, y, z))) * h_inv)).
 real_vec_t temp_vec21 = temp_vec20;

 // Define value at k_0(t, x, y, z).
 
 // Write aligned vector block to k_0 at t, x, y, z.
 _context->k_0->writeVecNorm(temp_vec21, tv, xv, yv, zv, __LINE__);

 // Read aligned vector block from k_1 at t, x, y+1, z.
 real_vec_t temp_vec22 =  _context->k_1->readVecNorm(tv, xv, yv + (1 / VLEN_Y), zv, __LINE__);

 // Read aligned vector block from k_1 at t, x, y-1, z.
 real_vec_t temp_vec23 =  _context->k_1->readVecNorm(tv, xv, yv - (1 / VLEN_Y), zv, __LINE__);

 // Read aligned vector block from k_1 at t, x, y, z.
 real_vec_t temp_vec24 =  _context->k_1->readVecNorm(tv, xv, yv, zv, __LINE__);

 // Read aligned vector block from k_1 at t, x, y, z+4.
 real_vec_t temp_vec25 =  _context->k_1->readVecNorm(tv, xv, yv, zv + (4 / VLEN_Z), __LINE__);

 // Construct unaligned vector block from k_1 at t, x, y, z+1.
 real_vec_t temp_vec26;
 // temp_vec26[0] = temp_vec24[1];  // for t, x, y, z+1;
 // temp_vec26[1] = temp_vec24[2];  // for t, x, y, z+2;
 // temp_vec26[2] = temp_vec24[3];  // for t, x, y, z+3;
 // temp_vec26[3] = temp_vec25[0];  // for t, x, y, z+4;
 // Get 1 element(s) from temp_vec25 and 3 from temp_vec24.
 real_vec_align<1>(temp_vec26, temp_vec25, temp_vec24);

 // Read aligned vector block from k_1 at t, x, y, z-4.
 real_vec_t temp_vec27 =  _context->k_1->readVecNorm(tv, xv, yv, zv - (4 / VLEN_Z), __LINE__);

 // Construct unaligned vector block from k_1 at t, x, y, z-1.
 real_vec_t temp_vec28;
 // temp_vec28[0] = temp_vec27[3];  // for t, x, y, z-1;
 // temp_vec28[1] = temp_vec24[0];  // for t, x, y, z;
 // temp_vec28[2] = temp_vec24[1];  // for t, x, y, z+1;
 // temp_vec28[3] = temp_vec24[2];  // for t, x, y, z+2;
 // Get 3 element(s) from temp_vec24 and 1 from temp_vec27.
 real_vec_align<3>(temp_vec28, temp_vec24, temp_vec27);

 // temp_vec29 = 1 * k_1(t, x, y+1, z).
 real_vec_t temp_vec29 = 1.00000000000000000e+00 * temp_vec22;

 // temp_vec30 = 1 * k_1(t, x, y-1, z).
 real_vec_t temp_vec30 = 1.00000000000000000e+00 * temp_vec23;

 // temp_vec31 = (1 * k_1(t, x, y+1, z)) + (1 * k_1(t, x, y-1, z)).
 real_vec_t temp_vec31 = temp_vec29 + temp_vec30;

 // temp_vec32 = 1 * k_1(t, x, y, z+1).
 real_vec_t temp_vec32 = 1.00000000000000000e+00 * temp_vec26;

 // temp_vec33 = (1 * k_1(t, x, y+1, z)) + (1 * k_1(t, x, y-1, z)) + (1 * k_1(t, x, y, z+1)).
 real_vec_t temp_vec33 = temp_vec31 + temp_vec32;

 // temp_vec34 = 1 * k_1(t, x, y, z-1).
 real_vec_t temp_vec34 = 1.00000000000000000e+00 * temp_vec28;

 // temp_vec35 = (1 * k_1(t, x, y+1, z)) + (1 * k_1(t, x, y-1, z)) + (1 * k_1(t, x, y, z+1)) + (1 * k_1(t, x, y, z-1)).
 real_vec_t temp_vec35 = temp_vec33 + temp_vec34;

 // temp_vec36 = -4 * k_1(t, x, y, z).
 real_vec_t temp_vec36 = -4.00000000000000000e+00 * temp_vec24;

 // temp_vec37 = (1 * k_1(t, x, y+1, z)) + (1 * k_1(t, x, y-1, z)) + (1 * k_1(t, x, y, z+1)) + (1 * k_1(t, x, y, z-1)) + (-4 * k_1(t, x, y, z)).
 real_vec_t temp_vec37 = temp_vec35 + temp_vec36;

 // temp_vec38 = ((1 * k_1(t, x, y+1, z)) + (1 * k_1(t, x, y-1, z)) + (1 * k_1(t, x, y, z+1)) + (1 * k_1(t, x, y, z-1)) + (-4 * k_1(t, x, y, z))) * h_inv().
 real_vec_t temp_vec38 = temp_vec37 * (*_context->h_inv)();

 // temp_vec39 = (0 * k_2(t, x, y, z)) + (((1 * k_1(t, x, y+1, z)) + (1 * k_1(t, x, y-1, z)) + (1 * k_1(t, x, y, z+1)) + (1 * k_1(t, x, y, z-1)) + (-4 * k_1(t, x, y, z))) * h_inv).
 real_vec_t temp_vec39 = temp_vec9 + temp_vec38;

 // temp_vec40 = ((0 * k_2(t, x, y, z)) + (((1 * k_1(t, x, y+1, z)) + (1 * k_1(t, x, y-1, z)) + (1 * k_1(t, x, y, z+1)) + (1 * k_1(t, x, y, z-1)) + (-4 * k_1(t, x, y, z))) * h_inv)).
 real_vec_t temp_vec40 = temp_vec39;

 // Define value at k_1(t, x, y, z).
 
 // Write aligned vector block to k_1 at t, x, y, z.
 _context->k_1->writeVecNorm(temp_vec40, tv, xv, yv, zv, __LINE__);
} // calc_cluster.

 // Simple shim function to map sub-block start vars to simple vars (ignoring stop vars).
 inline void calc_cluster(idx_t start_sbtv, idx_t start_sbwv, idx_t start_sbxv, idx_t start_sbyv, idx_t start_sbzv, idx_t stop_sbwv, idx_t stop_sbxv, idx_t stop_sbyv, idx_t stop_sbzv) {
 idx_t tv = start_sbtv;
 idx_t xv = start_sbxv;
 idx_t yv = start_sbyv;
 idx_t zv = start_sbzv;
 calc_cluster(tv, xv, yv, zv);
} // calc_cluster shim.

 // Prefetches cache line(s) for entire stencil relative to indices t, x, y, z in a 'x=1 * y=1 * z=4' cluster containing 1 'x=1 * y=1 * z=4' vector(s).
 // Indices must be normalized, i.e., already divided by VLEN_*.
 template<int level> inline void prefetch_cluster(idx_t tv, idx_t xv, idx_t yv, idx_t zv) {

 // Aligned k_0 at t, x, y-1, z.
 _context->k_0->prefetchVecNorm<level>(tv, xv, yv - (1 / VLEN_Y), zv, __LINE__);

 // Aligned k_0 at t, x, y, z-4.
 _context->k_0->prefetchVecNorm<level>(tv, xv, yv, zv - (4 / VLEN_Z), __LINE__);

 // Aligned k_0 at t, x, y, z.
 _context->k_0->prefetchVecNorm<level>(tv, xv, yv, zv, __LINE__);

 // Aligned k_0 at t, x, y, z+4.
 _context->k_0->prefetchVecNorm<level>(tv, xv, yv, zv + (4 / VLEN_Z), __LINE__);

 // Aligned k_0 at t, x, y+1, z.
 _context->k_0->prefetchVecNorm<level>(tv, xv, yv + (1 / VLEN_Y), zv, __LINE__);

 // Aligned k_1 at t, x, y-1, z.
 _context->k_1->prefetchVecNorm<level>(tv, xv, yv - (1 / VLEN_Y), zv, __LINE__);

 // Aligned k_1 at t, x, y, z-4.
 _context->k_1->prefetchVecNorm<level>(tv, xv, yv, zv - (4 / VLEN_Z), __LINE__);

 // Aligned k_1 at t, x, y, z.
 _context->k_1->prefetchVecNorm<level>(tv, xv, yv, zv, __LINE__);

 // Aligned k_1 at t, x, y, z+4.
 _context->k_1->prefetchVecNorm<level>(tv, xv, yv, zv + (4 / VLEN_Z), __LINE__);

 // Aligned k_1 at t, x, y+1, z.
 _context->k_1->prefetchVecNorm<level>(tv, xv, yv + (1 / VLEN_Y), zv, __LINE__);

 // Aligned k_2 at t, x, y, z.
 _context->k_2->prefetchVecNorm<level>(tv, xv, yv, zv, __LINE__);
} // prefetch_cluster.

 // Simple shim function to map sub-block start vars to simple vars (ignoring stop vars).
 template <int level> inline void prefetch_cluster(idx_t start_sbtv, idx_t start_sbwv, idx_t start_sbxv, idx_t start_sbyv, idx_t start_sbzv, idx_t stop_sbwv, idx_t stop_sbxv, idx_t stop_sbyv, idx_t stop_sbzv) {
 idx_t tv = start_sbtv;
 idx_t xv = start_sbxv;
 idx_t yv = start_sbyv;
 idx_t zv = start_sbzv;
 prefetch_cluster<level>(tv, xv, yv, zv);
} // prefetch_cluster shim.

 // Prefetches cache line(s) for leading edge of stencil advancing by 1 vector(s) in '+x' direction relative to indices t, x, y, z in a 'x=1 * y=1 * z=4' cluster containing 1 'x=1 * y=1 * z=4' vector(s).
 // Indices must be normalized, i.e., already divided by VLEN_*.
 template<int level> inline void prefetch_cluster_x(idx_t tv, idx_t xv, idx_t yv, idx_t zv) {

 // Aligned k_0 at t, x, y-1, z.
 _context->k_0->prefetchVecNorm<level>(tv, xv, yv - (1 / VLEN_Y), zv, __LINE__);

 // Aligned k_0 at t, x, y, z-4.
 _context->k_0->prefetchVecNorm<level>(tv, xv, yv, zv - (4 / VLEN_Z), __LINE__);

 // Aligned k_0 at t, x, y, z.
 _context->k_0->prefetchVecNorm<level>(tv, xv, yv, zv, __LINE__);

 // Aligned k_0 at t, x, y, z+4.
 _context->k_0->prefetchVecNorm<level>(tv, xv, yv, zv + (4 / VLEN_Z), __LINE__);

 // Aligned k_0 at t, x, y+1, z.
 _context->k_0->prefetchVecNorm<level>(tv, xv, yv + (1 / VLEN_Y), zv, __LINE__);

 // Aligned k_1 at t, x, y-1, z.
 _context->k_1->prefetchVecNorm<level>(tv, xv, yv - (1 / VLEN_Y), zv, __LINE__);

 // Aligned k_1 at t, x, y, z-4.
 _context->k_1->prefetchVecNorm<level>(tv, xv, yv, zv - (4 / VLEN_Z), __LINE__);

 // Aligned k_1 at t, x, y, z.
 _context->k_1->prefetchVecNorm<level>(tv, xv, yv, zv, __LINE__);

 // Aligned k_1 at t, x, y, z+4.
 _context->k_1->prefetchVecNorm<level>(tv, xv, yv, zv + (4 / VLEN_Z), __LINE__);

 // Aligned k_1 at t, x, y+1, z.
 _context->k_1->prefetchVecNorm<level>(tv, xv, yv + (1 / VLEN_Y), zv, __LINE__);

 // Aligned k_2 at t, x, y, z.
 _context->k_2->prefetchVecNorm<level>(tv, xv, yv, zv, __LINE__);
} // prefetch_cluster_x.

 // Simple shim function to map sub-block start vars to simple vars (ignoring stop vars).
 template <int level> inline void prefetch_cluster_sbxv(idx_t start_sbtv, idx_t start_sbwv, idx_t start_sbxv, idx_t start_sbyv, idx_t start_sbzv, idx_t stop_sbwv, idx_t stop_sbxv, idx_t stop_sbyv, idx_t stop_sbzv) {
 idx_t tv = start_sbtv;
 idx_t xv = start_sbxv;
 idx_t yv = start_sbyv;
 idx_t zv = start_sbzv;
 prefetch_cluster_x<level>(tv, xv, yv, zv);
} // prefetch_cluster shim.

 // Prefetches cache line(s) for leading edge of stencil advancing by 1 vector(s) in '+y' direction relative to indices t, x, y, z in a 'x=1 * y=1 * z=4' cluster containing 1 'x=1 * y=1 * z=4' vector(s).
 // Indices must be normalized, i.e., already divided by VLEN_*.
 template<int level> inline void prefetch_cluster_y(idx_t tv, idx_t xv, idx_t yv, idx_t zv) {

 // Aligned k_0 at t, x, y, z-4.
 _context->k_0->prefetchVecNorm<level>(tv, xv, yv, zv - (4 / VLEN_Z), __LINE__);

 // Aligned k_0 at t, x, y, z+4.
 _context->k_0->prefetchVecNorm<level>(tv, xv, yv, zv + (4 / VLEN_Z), __LINE__);

 // Aligned k_0 at t, x, y+1, z.
 _context->k_0->prefetchVecNorm<level>(tv, xv, yv + (1 / VLEN_Y), zv, __LINE__);

 // Aligned k_1 at t, x, y, z-4.
 _context->k_1->prefetchVecNorm<level>(tv, xv, yv, zv - (4 / VLEN_Z), __LINE__);

 // Aligned k_1 at t, x, y, z+4.
 _context->k_1->prefetchVecNorm<level>(tv, xv, yv, zv + (4 / VLEN_Z), __LINE__);

 // Aligned k_1 at t, x, y+1, z.
 _context->k_1->prefetchVecNorm<level>(tv, xv, yv + (1 / VLEN_Y), zv, __LINE__);

 // Aligned k_2 at t, x, y, z.
 _context->k_2->prefetchVecNorm<level>(tv, xv, yv, zv, __LINE__);
} // prefetch_cluster_y.

 // Simple shim function to map sub-block start vars to simple vars (ignoring stop vars).
 template <int level> inline void prefetch_cluster_sbyv(idx_t start_sbtv, idx_t start_sbwv, idx_t start_sbxv, idx_t start_sbyv, idx_t start_sbzv, idx_t stop_sbwv, idx_t stop_sbxv, idx_t stop_sbyv, idx_t stop_sbzv) {
 idx_t tv = start_sbtv;
 idx_t xv = start_sbxv;
 idx_t yv = start_sbyv;
 idx_t zv = start_sbzv;
 prefetch_cluster_y<level>(tv, xv, yv, zv);
} // prefetch_cluster shim.

 // Prefetches cache line(s) for leading edge of stencil advancing by 1 vector(s) in '+z' direction relative to indices t, x, y, z in a 'x=1 * y=1 * z=4' cluster containing 1 'x=1 * y=1 * z=4' vector(s).
 // Indices must be normalized, i.e., already divided by VLEN_*.
 template<int level> inline void prefetch_cluster_z(idx_t tv, idx_t xv, idx_t yv, idx_t zv) {

 // Aligned k_0 at t, x, y-1, z.
 _context->k_0->prefetchVecNorm<level>(tv, xv, yv - (1 / VLEN_Y), zv, __LINE__);

 // Aligned k_0 at t, x, y, z+4.
 _context->k_0->prefetchVecNorm<level>(tv, xv, yv, zv + (4 / VLEN_Z), __LINE__);

 // Aligned k_0 at t, x, y+1, z.
 _context->k_0->prefetchVecNorm<level>(tv, xv, yv + (1 / VLEN_Y), zv, __LINE__);

 // Aligned k_1 at t, x, y-1, z.
 _context->k_1->prefetchVecNorm<level>(tv, xv, yv - (1 / VLEN_Y), zv, __LINE__);

 // Aligned k_1 at t, x, y, z+4.
 _context->k_1->prefetchVecNorm<level>(tv, xv, yv, zv + (4 / VLEN_Z), __LINE__);

 // Aligned k_1 at t, x, y+1, z.
 _context->k_1->prefetchVecNorm<level>(tv, xv, yv + (1 / VLEN_Y), zv, __LINE__);

 // Aligned k_2 at t, x, y, z.
 _context->k_2->prefetchVecNorm<level>(tv, xv, yv, zv, __LINE__);
} // prefetch_cluster_z.

 // Simple shim function to map sub-block start vars to simple vars (ignoring stop vars).
 template <int level> inline void prefetch_cluster_sbzv(idx_t start_sbtv, idx_t start_sbwv, idx_t start_sbxv, idx_t start_sbyv, idx_t start_sbzv, idx_t stop_sbwv, idx_t stop_sbxv, idx_t stop_sbyv, idx_t stop_sbzv) {
 idx_t tv = start_sbtv;
 idx_t xv = start_sbxv;
 idx_t yv = start_sbyv;
 idx_t zv = start_sbzv;
 prefetch_cluster_z<level>(tv, xv, yv, zv);
} // prefetch_cluster shim.

 // Calculate one sub-block of whole clusters.
 virtual void calc_sub_block_of_clusters(idx_t begin_sbtv, idx_t begin_sbxv, idx_t begin_sbyv, idx_t begin_sbzv, idx_t end_sbtv, idx_t end_sbxv, idx_t end_sbyv, idx_t end_sbzv) {

 // Steps and group sizes are based on cluster lengths.
 const idx_t step_sbtv = CLEN_T;
 const idx_t group_size_sbtv = CLEN_T;
 const idx_t step_sbxv = CLEN_X;
 const idx_t group_size_sbxv = CLEN_X;
 const idx_t step_sbyv = CLEN_Y;
 const idx_t group_size_sbyv = CLEN_Y;
 const idx_t step_sbzv = CLEN_Z;
 const idx_t group_size_sbzv = CLEN_Z;
 const idx_t begin_sbwv = 0; // not used in this stencil.
 const idx_t end_sbwv = 1;
 const idx_t step_sbwv = CLEN_W;
 const idx_t group_size_sbwv = CLEN_W;
 #if !defined(DEBUG) && defined(__INTEL_COMPILER)
 #pragma forceinline recursive
 #endif
 {
  // Include automatically-generated loop code that calls calc_cluster()  and optionally, the prefetch function(s).
  #include "stencil_sub_block_loops.hpp"
 }
} // calc_sub_block_of_clusters
}; // EqGroup_stencil_1.

 ////// Stencil equation-group 'stencil_2' w/no condition //////

 class EqGroup_stencil_2 : public EqGroupBase {
 protected:
 StencilContext_ys_RHS_LC_emb_jil_yasksite_Heat2D_data* _context = 0;
 public:

 // 12 FP operation(s) per point:
 // k_2(t, x, y, z) EQUALS ((0 * k_2(t, x, y, z)) + (((1 * k_2(t, x, y+1, z)) + (1 * k_2(t, x, y-1, z)) + (1 * k_2(t, x, y, z+1)) + (1 * k_2(t, x, y, z-1)) + (-4 * k_2(t, x, y, z))) * h_inv)).
 EqGroup_stencil_2(StencilContext_ys_RHS_LC_emb_jil_yasksite_Heat2D_data* context) :
 EqGroupBase(context),
 _context(context) {
 _name = "stencil_2";
 _scalar_fp_ops = 12;
 _scalar_points_read = 5;
 _scalar_points_written = 1;

 // The following grids are written by EqGroup_stencil_2
  outputGridPtrs.push_back(_context->k_2);

 // The following grids are read by EqGroup_stencil_2
  inputGridPtrs.push_back(_context->k_2);
 } // Ctor.

 // Determine whether EqGroup_stencil_2 is valid at the given indices. Return true if indices are within the valid sub-domain or false otherwise.
 virtual bool is_in_valid_domain(idx_t t, idx_t x, idx_t y, idx_t z) {
 return (x>=FIRST_INDEX(x)) && (x<=LAST_INDEX(x)) && (y>=FIRST_INDEX(y)) && (y<=LAST_INDEX(y)) && (z>=FIRST_INDEX(z)) && (z<=LAST_INDEX(z)); // full domain.
 }

 // Calculate one scalar result relative to indices t, x, y, z.
 virtual void calc_scalar(idx_t t, idx_t x, idx_t y, idx_t z) {

 // temp1 = 0 * k_2(t, x, y, z).
 real_t temp1 = 0.00000000000000000e+00 * _context->k_2->readElem(t, x, y, z, __LINE__);

 // temp2 = 1 * k_2(t, x, y+1, z).
 real_t temp2 = 1.00000000000000000e+00 * _context->k_2->readElem(t, x, y+1, z, __LINE__);

 // temp3 = 1 * k_2(t, x, y-1, z).
 real_t temp3 = 1.00000000000000000e+00 * _context->k_2->readElem(t, x, y-1, z, __LINE__);

 // temp4 = (1 * k_2(t, x, y+1, z)) + (1 * k_2(t, x, y-1, z)).
 real_t temp4 = temp2 + temp3;

 // temp5 = 1 * k_2(t, x, y, z+1).
 real_t temp5 = 1.00000000000000000e+00 * _context->k_2->readElem(t, x, y, z+1, __LINE__);

 // temp6 = (1 * k_2(t, x, y+1, z)) + (1 * k_2(t, x, y-1, z)) + (1 * k_2(t, x, y, z+1)).
 real_t temp6 = temp4 + temp5;

 // temp7 = 1 * k_2(t, x, y, z-1).
 real_t temp7 = 1.00000000000000000e+00 * _context->k_2->readElem(t, x, y, z-1, __LINE__);

 // temp8 = (1 * k_2(t, x, y+1, z)) + (1 * k_2(t, x, y-1, z)) + (1 * k_2(t, x, y, z+1)) + (1 * k_2(t, x, y, z-1)).
 real_t temp8 = temp6 + temp7;

 // temp9 = -4 * k_2(t, x, y, z).
 real_t temp9 = -4.00000000000000000e+00 * _context->k_2->readElem(t, x, y, z, __LINE__);

 // temp10 = (1 * k_2(t, x, y+1, z)) + (1 * k_2(t, x, y-1, z)) + (1 * k_2(t, x, y, z+1)) + (1 * k_2(t, x, y, z-1)) + (-4 * k_2(t, x, y, z)).
 real_t temp10 = temp8 + temp9;

 // temp11 = ((1 * k_2(t, x, y+1, z)) + (1 * k_2(t, x, y-1, z)) + (1 * k_2(t, x, y, z+1)) + (1 * k_2(t, x, y, z-1)) + (-4 * k_2(t, x, y, z))) * h_inv().
 real_t temp11 = temp10 * (*_context->h_inv)();

 // temp12 = (0 * k_2(t, x, y, z)) + (((1 * k_2(t, x, y+1, z)) + (1 * k_2(t, x, y-1, z)) + (1 * k_2(t, x, y, z+1)) + (1 * k_2(t, x, y, z-1)) + (-4 * k_2(t, x, y, z))) * h_inv).
 real_t temp12 = temp1 + temp11;

 // temp13 = ((0 * k_2(t, x, y, z)) + (((1 * k_2(t, x, y+1, z)) + (1 * k_2(t, x, y-1, z)) + (1 * k_2(t, x, y, z+1)) + (1 * k_2(t, x, y, z-1)) + (-4 * k_2(t, x, y, z))) * h_inv)).
 real_t temp13 = temp12;

 // Define value at k_2(t, x, y, z).
 _context->k_2->writeElem(temp13, t, x, y, z, __LINE__);
} // calc_scalar.

 // Calculate 4 result(s) relative to indices t, x, y, z in a 'x=1 * y=1 * z=4' cluster containing 1 'x=1 * y=1 * z=4' vector(s).
 // Indices must be normalized, i.e., already divided by VLEN_*.
 // SIMD calculations use 5 vector block(s) created from 5 aligned vector-block(s).
 // There are approximately 48 FP operation(s) per invocation.
 inline void calc_cluster(idx_t tv, idx_t xv, idx_t yv, idx_t zv) {

 // Element (un-normalized) indices.
 idx_t t = tv;
 idx_t x = xv * VLEN_X;
 idx_t y = yv * VLEN_Y;
 idx_t z = zv * VLEN_Z;

 // Read aligned vector block from k_2 at t, x, y, z.
 real_vec_t temp_vec1 =  _context->k_2->readVecNorm(tv, xv, yv, zv, __LINE__);

 // Read aligned vector block from k_2 at t, x, y+1, z.
 real_vec_t temp_vec2 =  _context->k_2->readVecNorm(tv, xv, yv + (1 / VLEN_Y), zv, __LINE__);

 // Read aligned vector block from k_2 at t, x, y-1, z.
 real_vec_t temp_vec3 =  _context->k_2->readVecNorm(tv, xv, yv - (1 / VLEN_Y), zv, __LINE__);

 // Read aligned vector block from k_2 at t, x, y, z+4.
 real_vec_t temp_vec4 =  _context->k_2->readVecNorm(tv, xv, yv, zv + (4 / VLEN_Z), __LINE__);

 // Construct unaligned vector block from k_2 at t, x, y, z+1.
 real_vec_t temp_vec5;
 // temp_vec5[0] = temp_vec1[1];  // for t, x, y, z+1;
 // temp_vec5[1] = temp_vec1[2];  // for t, x, y, z+2;
 // temp_vec5[2] = temp_vec1[3];  // for t, x, y, z+3;
 // temp_vec5[3] = temp_vec4[0];  // for t, x, y, z+4;
 // Get 1 element(s) from temp_vec4 and 3 from temp_vec1.
 real_vec_align<1>(temp_vec5, temp_vec4, temp_vec1);

 // Read aligned vector block from k_2 at t, x, y, z-4.
 real_vec_t temp_vec6 =  _context->k_2->readVecNorm(tv, xv, yv, zv - (4 / VLEN_Z), __LINE__);

 // Construct unaligned vector block from k_2 at t, x, y, z-1.
 real_vec_t temp_vec7;
 // temp_vec7[0] = temp_vec6[3];  // for t, x, y, z-1;
 // temp_vec7[1] = temp_vec1[0];  // for t, x, y, z;
 // temp_vec7[2] = temp_vec1[1];  // for t, x, y, z+1;
 // temp_vec7[3] = temp_vec1[2];  // for t, x, y, z+2;
 // Get 3 element(s) from temp_vec1 and 1 from temp_vec6.
 real_vec_align<3>(temp_vec7, temp_vec1, temp_vec6);

 // temp_vec8 = 0 * k_2(t, x, y, z).
 real_vec_t temp_vec8 = 0.00000000000000000e+00 * temp_vec1;

 // temp_vec9 = 1 * k_2(t, x, y+1, z).
 real_vec_t temp_vec9 = 1.00000000000000000e+00 * temp_vec2;

 // temp_vec10 = 1 * k_2(t, x, y-1, z).
 real_vec_t temp_vec10 = 1.00000000000000000e+00 * temp_vec3;

 // temp_vec11 = (1 * k_2(t, x, y+1, z)) + (1 * k_2(t, x, y-1, z)).
 real_vec_t temp_vec11 = temp_vec9 + temp_vec10;

 // temp_vec12 = 1 * k_2(t, x, y, z+1).
 real_vec_t temp_vec12 = 1.00000000000000000e+00 * temp_vec5;

 // temp_vec13 = (1 * k_2(t, x, y+1, z)) + (1 * k_2(t, x, y-1, z)) + (1 * k_2(t, x, y, z+1)).
 real_vec_t temp_vec13 = temp_vec11 + temp_vec12;

 // temp_vec14 = 1 * k_2(t, x, y, z-1).
 real_vec_t temp_vec14 = 1.00000000000000000e+00 * temp_vec7;

 // temp_vec15 = (1 * k_2(t, x, y+1, z)) + (1 * k_2(t, x, y-1, z)) + (1 * k_2(t, x, y, z+1)) + (1 * k_2(t, x, y, z-1)).
 real_vec_t temp_vec15 = temp_vec13 + temp_vec14;

 // temp_vec16 = -4 * k_2(t, x, y, z).
 real_vec_t temp_vec16 = -4.00000000000000000e+00 * temp_vec1;

 // temp_vec17 = (1 * k_2(t, x, y+1, z)) + (1 * k_2(t, x, y-1, z)) + (1 * k_2(t, x, y, z+1)) + (1 * k_2(t, x, y, z-1)) + (-4 * k_2(t, x, y, z)).
 real_vec_t temp_vec17 = temp_vec15 + temp_vec16;

 // temp_vec18 = ((1 * k_2(t, x, y+1, z)) + (1 * k_2(t, x, y-1, z)) + (1 * k_2(t, x, y, z+1)) + (1 * k_2(t, x, y, z-1)) + (-4 * k_2(t, x, y, z))) * h_inv().
 real_vec_t temp_vec18 = temp_vec17 * (*_context->h_inv)();

 // temp_vec19 = (0 * k_2(t, x, y, z)) + (((1 * k_2(t, x, y+1, z)) + (1 * k_2(t, x, y-1, z)) + (1 * k_2(t, x, y, z+1)) + (1 * k_2(t, x, y, z-1)) + (-4 * k_2(t, x, y, z))) * h_inv).
 real_vec_t temp_vec19 = temp_vec8 + temp_vec18;

 // temp_vec20 = ((0 * k_2(t, x, y, z)) + (((1 * k_2(t, x, y+1, z)) + (1 * k_2(t, x, y-1, z)) + (1 * k_2(t, x, y, z+1)) + (1 * k_2(t, x, y, z-1)) + (-4 * k_2(t, x, y, z))) * h_inv)).
 real_vec_t temp_vec20 = temp_vec19;

 // Define value at k_2(t, x, y, z).
 
 // Write aligned vector block to k_2 at t, x, y, z.
 _context->k_2->writeVecNorm(temp_vec20, tv, xv, yv, zv, __LINE__);
} // calc_cluster.

 // Simple shim function to map sub-block start vars to simple vars (ignoring stop vars).
 inline void calc_cluster(idx_t start_sbtv, idx_t start_sbwv, idx_t start_sbxv, idx_t start_sbyv, idx_t start_sbzv, idx_t stop_sbwv, idx_t stop_sbxv, idx_t stop_sbyv, idx_t stop_sbzv) {
 idx_t tv = start_sbtv;
 idx_t xv = start_sbxv;
 idx_t yv = start_sbyv;
 idx_t zv = start_sbzv;
 calc_cluster(tv, xv, yv, zv);
} // calc_cluster shim.

 // Prefetches cache line(s) for entire stencil relative to indices t, x, y, z in a 'x=1 * y=1 * z=4' cluster containing 1 'x=1 * y=1 * z=4' vector(s).
 // Indices must be normalized, i.e., already divided by VLEN_*.
 template<int level> inline void prefetch_cluster(idx_t tv, idx_t xv, idx_t yv, idx_t zv) {

 // Aligned k_2 at t, x, y-1, z.
 _context->k_2->prefetchVecNorm<level>(tv, xv, yv - (1 / VLEN_Y), zv, __LINE__);

 // Aligned k_2 at t, x, y, z-4.
 _context->k_2->prefetchVecNorm<level>(tv, xv, yv, zv - (4 / VLEN_Z), __LINE__);

 // Aligned k_2 at t, x, y, z.
 _context->k_2->prefetchVecNorm<level>(tv, xv, yv, zv, __LINE__);

 // Aligned k_2 at t, x, y, z+4.
 _context->k_2->prefetchVecNorm<level>(tv, xv, yv, zv + (4 / VLEN_Z), __LINE__);

 // Aligned k_2 at t, x, y+1, z.
 _context->k_2->prefetchVecNorm<level>(tv, xv, yv + (1 / VLEN_Y), zv, __LINE__);
} // prefetch_cluster.

 // Simple shim function to map sub-block start vars to simple vars (ignoring stop vars).
 template <int level> inline void prefetch_cluster(idx_t start_sbtv, idx_t start_sbwv, idx_t start_sbxv, idx_t start_sbyv, idx_t start_sbzv, idx_t stop_sbwv, idx_t stop_sbxv, idx_t stop_sbyv, idx_t stop_sbzv) {
 idx_t tv = start_sbtv;
 idx_t xv = start_sbxv;
 idx_t yv = start_sbyv;
 idx_t zv = start_sbzv;
 prefetch_cluster<level>(tv, xv, yv, zv);
} // prefetch_cluster shim.

 // Prefetches cache line(s) for leading edge of stencil advancing by 1 vector(s) in '+x' direction relative to indices t, x, y, z in a 'x=1 * y=1 * z=4' cluster containing 1 'x=1 * y=1 * z=4' vector(s).
 // Indices must be normalized, i.e., already divided by VLEN_*.
 template<int level> inline void prefetch_cluster_x(idx_t tv, idx_t xv, idx_t yv, idx_t zv) {

 // Aligned k_2 at t, x, y-1, z.
 _context->k_2->prefetchVecNorm<level>(tv, xv, yv - (1 / VLEN_Y), zv, __LINE__);

 // Aligned k_2 at t, x, y, z-4.
 _context->k_2->prefetchVecNorm<level>(tv, xv, yv, zv - (4 / VLEN_Z), __LINE__);

 // Aligned k_2 at t, x, y, z.
 _context->k_2->prefetchVecNorm<level>(tv, xv, yv, zv, __LINE__);

 // Aligned k_2 at t, x, y, z+4.
 _context->k_2->prefetchVecNorm<level>(tv, xv, yv, zv + (4 / VLEN_Z), __LINE__);

 // Aligned k_2 at t, x, y+1, z.
 _context->k_2->prefetchVecNorm<level>(tv, xv, yv + (1 / VLEN_Y), zv, __LINE__);
} // prefetch_cluster_x.

 // Simple shim function to map sub-block start vars to simple vars (ignoring stop vars).
 template <int level> inline void prefetch_cluster_sbxv(idx_t start_sbtv, idx_t start_sbwv, idx_t start_sbxv, idx_t start_sbyv, idx_t start_sbzv, idx_t stop_sbwv, idx_t stop_sbxv, idx_t stop_sbyv, idx_t stop_sbzv) {
 idx_t tv = start_sbtv;
 idx_t xv = start_sbxv;
 idx_t yv = start_sbyv;
 idx_t zv = start_sbzv;
 prefetch_cluster_x<level>(tv, xv, yv, zv);
} // prefetch_cluster shim.

 // Prefetches cache line(s) for leading edge of stencil advancing by 1 vector(s) in '+y' direction relative to indices t, x, y, z in a 'x=1 * y=1 * z=4' cluster containing 1 'x=1 * y=1 * z=4' vector(s).
 // Indices must be normalized, i.e., already divided by VLEN_*.
 template<int level> inline void prefetch_cluster_y(idx_t tv, idx_t xv, idx_t yv, idx_t zv) {

 // Aligned k_2 at t, x, y, z-4.
 _context->k_2->prefetchVecNorm<level>(tv, xv, yv, zv - (4 / VLEN_Z), __LINE__);

 // Aligned k_2 at t, x, y, z+4.
 _context->k_2->prefetchVecNorm<level>(tv, xv, yv, zv + (4 / VLEN_Z), __LINE__);

 // Aligned k_2 at t, x, y+1, z.
 _context->k_2->prefetchVecNorm<level>(tv, xv, yv + (1 / VLEN_Y), zv, __LINE__);
} // prefetch_cluster_y.

 // Simple shim function to map sub-block start vars to simple vars (ignoring stop vars).
 template <int level> inline void prefetch_cluster_sbyv(idx_t start_sbtv, idx_t start_sbwv, idx_t start_sbxv, idx_t start_sbyv, idx_t start_sbzv, idx_t stop_sbwv, idx_t stop_sbxv, idx_t stop_sbyv, idx_t stop_sbzv) {
 idx_t tv = start_sbtv;
 idx_t xv = start_sbxv;
 idx_t yv = start_sbyv;
 idx_t zv = start_sbzv;
 prefetch_cluster_y<level>(tv, xv, yv, zv);
} // prefetch_cluster shim.

 // Prefetches cache line(s) for leading edge of stencil advancing by 1 vector(s) in '+z' direction relative to indices t, x, y, z in a 'x=1 * y=1 * z=4' cluster containing 1 'x=1 * y=1 * z=4' vector(s).
 // Indices must be normalized, i.e., already divided by VLEN_*.
 template<int level> inline void prefetch_cluster_z(idx_t tv, idx_t xv, idx_t yv, idx_t zv) {

 // Aligned k_2 at t, x, y-1, z.
 _context->k_2->prefetchVecNorm<level>(tv, xv, yv - (1 / VLEN_Y), zv, __LINE__);

 // Aligned k_2 at t, x, y, z+4.
 _context->k_2->prefetchVecNorm<level>(tv, xv, yv, zv + (4 / VLEN_Z), __LINE__);

 // Aligned k_2 at t, x, y+1, z.
 _context->k_2->prefetchVecNorm<level>(tv, xv, yv + (1 / VLEN_Y), zv, __LINE__);
} // prefetch_cluster_z.

 // Simple shim function to map sub-block start vars to simple vars (ignoring stop vars).
 template <int level> inline void prefetch_cluster_sbzv(idx_t start_sbtv, idx_t start_sbwv, idx_t start_sbxv, idx_t start_sbyv, idx_t start_sbzv, idx_t stop_sbwv, idx_t stop_sbxv, idx_t stop_sbyv, idx_t stop_sbzv) {
 idx_t tv = start_sbtv;
 idx_t xv = start_sbxv;
 idx_t yv = start_sbyv;
 idx_t zv = start_sbzv;
 prefetch_cluster_z<level>(tv, xv, yv, zv);
} // prefetch_cluster shim.

 // Calculate one sub-block of whole clusters.
 virtual void calc_sub_block_of_clusters(idx_t begin_sbtv, idx_t begin_sbxv, idx_t begin_sbyv, idx_t begin_sbzv, idx_t end_sbtv, idx_t end_sbxv, idx_t end_sbyv, idx_t end_sbzv) {

 // Steps and group sizes are based on cluster lengths.
 const idx_t step_sbtv = CLEN_T;
 const idx_t group_size_sbtv = CLEN_T;
 const idx_t step_sbxv = CLEN_X;
 const idx_t group_size_sbxv = CLEN_X;
 const idx_t step_sbyv = CLEN_Y;
 const idx_t group_size_sbyv = CLEN_Y;
 const idx_t step_sbzv = CLEN_Z;
 const idx_t group_size_sbzv = CLEN_Z;
 const idx_t begin_sbwv = 0; // not used in this stencil.
 const idx_t end_sbwv = 1;
 const idx_t step_sbwv = CLEN_W;
 const idx_t group_size_sbwv = CLEN_W;
 #if !defined(DEBUG) && defined(__INTEL_COMPILER)
 #pragma forceinline recursive
 #endif
 {
  // Include automatically-generated loop code that calls calc_cluster()  and optionally, the prefetch function(s).
  #include "stencil_sub_block_loops.hpp"
 }
} // calc_sub_block_of_clusters
}; // EqGroup_stencil_2.

 ////// Stencil equation-group 'stencil_0' w/no condition //////

 class EqGroup_stencil_0 : public EqGroupBase {
 protected:
 StencilContext_ys_RHS_LC_emb_jil_yasksite_Heat2D_data* _context = 0;
 public:

 // 7 FP operation(s) per point:
 // data(t+1, x, y, z) EQUALS (data(t, x, y, z) + (dt * ((0.5 * k_0(t, x, y, z)) + (0.5 * k_1(t, x, y, z)) + (0 * k_2(t, x, y, z))))).
 EqGroup_stencil_0(StencilContext_ys_RHS_LC_emb_jil_yasksite_Heat2D_data* context) :
 EqGroupBase(context),
 _context(context) {
 _name = "stencil_0";
 _scalar_fp_ops = 7;
 _scalar_points_read = 4;
 _scalar_points_written = 1;

 // The following grids are written by EqGroup_stencil_0
  outputGridPtrs.push_back(_context->data);

 // The following grids are read by EqGroup_stencil_0
  inputGridPtrs.push_back(_context->k_2);
  inputGridPtrs.push_back(_context->k_1);
  inputGridPtrs.push_back(_context->k_0);
  inputGridPtrs.push_back(_context->data);
 } // Ctor.

 // Determine whether EqGroup_stencil_0 is valid at the given indices. Return true if indices are within the valid sub-domain or false otherwise.
 virtual bool is_in_valid_domain(idx_t t, idx_t x, idx_t y, idx_t z) {
 return (x>=FIRST_INDEX(x)) && (x<=LAST_INDEX(x)) && (y>=FIRST_INDEX(y)) && (y<=LAST_INDEX(y)) && (z>=FIRST_INDEX(z)) && (z<=LAST_INDEX(z)); // full domain.
 }

 // Calculate one scalar result relative to indices t, x, y, z.
 virtual void calc_scalar(idx_t t, idx_t x, idx_t y, idx_t z) {

 // temp1 = 0.5 * k_0(t, x, y, z).
 real_t temp1 = 5.00000000000000000e-01 * _context->k_0->readElem(t, x, y, z, __LINE__);

 // temp2 = 0.5 * k_1(t, x, y, z).
 real_t temp2 = 5.00000000000000000e-01 * _context->k_1->readElem(t, x, y, z, __LINE__);

 // temp3 = (0.5 * k_0(t, x, y, z)) + (0.5 * k_1(t, x, y, z)).
 real_t temp3 = temp1 + temp2;

 // temp4 = (0.5 * k_0(t, x, y, z)) + (0.5 * k_1(t, x, y, z)) + (0 * k_2(t, x, y, z)).
 real_t temp4 = temp3 + (0.00000000000000000e+00 * _context->k_2->readElem(t, x, y, z, __LINE__));

 // temp5 = dt() * ((0.5 * k_0(t, x, y, z)) + (0.5 * k_1(t, x, y, z)) + (0 * k_2(t, x, y, z))).
 real_t temp5 = (*_context->dt)() * temp4;

 // temp6 = data(t, x, y, z) + (dt * ((0.5 * k_0(t, x, y, z)) + (0.5 * k_1(t, x, y, z)) + (0 * k_2(t, x, y, z)))).
 real_t temp6 = _context->data->readElem(t, x, y, z, __LINE__) + temp5;

 // temp7 = (data(t, x, y, z) + (dt * ((0.5 * k_0(t, x, y, z)) + (0.5 * k_1(t, x, y, z)) + (0 * k_2(t, x, y, z))))).
 real_t temp7 = temp6;

 // Define value at data(t+1, x, y, z).
 _context->data->writeElem(temp7, t+1, x, y, z, __LINE__);
} // calc_scalar.

 // Calculate 4 result(s) relative to indices t, x, y, z in a 'x=1 * y=1 * z=4' cluster containing 1 'x=1 * y=1 * z=4' vector(s).
 // Indices must be normalized, i.e., already divided by VLEN_*.
 // SIMD calculations use 4 vector block(s) created from 4 aligned vector-block(s).
 // There are approximately 28 FP operation(s) per invocation.
 inline void calc_cluster(idx_t tv, idx_t xv, idx_t yv, idx_t zv) {

 // Element (un-normalized) indices.
 idx_t t = tv;
 idx_t x = xv * VLEN_X;
 idx_t y = yv * VLEN_Y;
 idx_t z = zv * VLEN_Z;

 // Read aligned vector block from data at t, x, y, z.
 real_vec_t temp_vec1 =  _context->data->readVecNorm(tv, xv, yv, zv, __LINE__);

 // Read aligned vector block from k_0 at t, x, y, z.
 real_vec_t temp_vec2 =  _context->k_0->readVecNorm(tv, xv, yv, zv, __LINE__);

 // Read aligned vector block from k_1 at t, x, y, z.
 real_vec_t temp_vec3 =  _context->k_1->readVecNorm(tv, xv, yv, zv, __LINE__);

 // Read aligned vector block from k_2 at t, x, y, z.
 real_vec_t temp_vec4 =  _context->k_2->readVecNorm(tv, xv, yv, zv, __LINE__);

 // temp_vec5 = 0.5 * k_0(t, x, y, z).
 real_vec_t temp_vec5 = 5.00000000000000000e-01 * temp_vec2;

 // temp_vec6 = 0.5 * k_1(t, x, y, z).
 real_vec_t temp_vec6 = 5.00000000000000000e-01 * temp_vec3;

 // temp_vec7 = (0.5 * k_0(t, x, y, z)) + (0.5 * k_1(t, x, y, z)).
 real_vec_t temp_vec7 = temp_vec5 + temp_vec6;

 // temp_vec8 = (0.5 * k_0(t, x, y, z)) + (0.5 * k_1(t, x, y, z)) + (0 * k_2(t, x, y, z)).
 real_vec_t temp_vec8 = temp_vec7 + (0.00000000000000000e+00 * temp_vec4);

 // temp_vec9 = dt() * ((0.5 * k_0(t, x, y, z)) + (0.5 * k_1(t, x, y, z)) + (0 * k_2(t, x, y, z))).
 real_vec_t temp_vec9 = (*_context->dt)() * temp_vec8;

 // temp_vec10 = data(t, x, y, z) + (dt * ((0.5 * k_0(t, x, y, z)) + (0.5 * k_1(t, x, y, z)) + (0 * k_2(t, x, y, z)))).
 real_vec_t temp_vec10 = temp_vec1 + temp_vec9;

 // temp_vec11 = (data(t, x, y, z) + (dt * ((0.5 * k_0(t, x, y, z)) + (0.5 * k_1(t, x, y, z)) + (0 * k_2(t, x, y, z))))).
 real_vec_t temp_vec11 = temp_vec10;

 // Define value at data(t+1, x, y, z).
 
 // Write aligned vector block to data at t+1, x, y, z.
 _context->data->writeVecNorm(temp_vec11, tv+1, xv, yv, zv, __LINE__);
} // calc_cluster.

 // Simple shim function to map sub-block start vars to simple vars (ignoring stop vars).
 inline void calc_cluster(idx_t start_sbtv, idx_t start_sbwv, idx_t start_sbxv, idx_t start_sbyv, idx_t start_sbzv, idx_t stop_sbwv, idx_t stop_sbxv, idx_t stop_sbyv, idx_t stop_sbzv) {
 idx_t tv = start_sbtv;
 idx_t xv = start_sbxv;
 idx_t yv = start_sbyv;
 idx_t zv = start_sbzv;
 calc_cluster(tv, xv, yv, zv);
} // calc_cluster shim.

 // Prefetches cache line(s) for entire stencil relative to indices t, x, y, z in a 'x=1 * y=1 * z=4' cluster containing 1 'x=1 * y=1 * z=4' vector(s).
 // Indices must be normalized, i.e., already divided by VLEN_*.
 template<int level> inline void prefetch_cluster(idx_t tv, idx_t xv, idx_t yv, idx_t zv) {

 // Aligned data at t, x, y, z.
 _context->data->prefetchVecNorm<level>(tv, xv, yv, zv, __LINE__);

 // Aligned k_0 at t, x, y, z.
 _context->k_0->prefetchVecNorm<level>(tv, xv, yv, zv, __LINE__);

 // Aligned k_1 at t, x, y, z.
 _context->k_1->prefetchVecNorm<level>(tv, xv, yv, zv, __LINE__);

 // Aligned k_2 at t, x, y, z.
 _context->k_2->prefetchVecNorm<level>(tv, xv, yv, zv, __LINE__);
} // prefetch_cluster.

 // Simple shim function to map sub-block start vars to simple vars (ignoring stop vars).
 template <int level> inline void prefetch_cluster(idx_t start_sbtv, idx_t start_sbwv, idx_t start_sbxv, idx_t start_sbyv, idx_t start_sbzv, idx_t stop_sbwv, idx_t stop_sbxv, idx_t stop_sbyv, idx_t stop_sbzv) {
 idx_t tv = start_sbtv;
 idx_t xv = start_sbxv;
 idx_t yv = start_sbyv;
 idx_t zv = start_sbzv;
 prefetch_cluster<level>(tv, xv, yv, zv);
} // prefetch_cluster shim.

 // Prefetches cache line(s) for leading edge of stencil advancing by 1 vector(s) in '+x' direction relative to indices t, x, y, z in a 'x=1 * y=1 * z=4' cluster containing 1 'x=1 * y=1 * z=4' vector(s).
 // Indices must be normalized, i.e., already divided by VLEN_*.
 template<int level> inline void prefetch_cluster_x(idx_t tv, idx_t xv, idx_t yv, idx_t zv) {

 // Aligned data at t, x, y, z.
 _context->data->prefetchVecNorm<level>(tv, xv, yv, zv, __LINE__);

 // Aligned k_0 at t, x, y, z.
 _context->k_0->prefetchVecNorm<level>(tv, xv, yv, zv, __LINE__);

 // Aligned k_1 at t, x, y, z.
 _context->k_1->prefetchVecNorm<level>(tv, xv, yv, zv, __LINE__);

 // Aligned k_2 at t, x, y, z.
 _context->k_2->prefetchVecNorm<level>(tv, xv, yv, zv, __LINE__);
} // prefetch_cluster_x.

 // Simple shim function to map sub-block start vars to simple vars (ignoring stop vars).
 template <int level> inline void prefetch_cluster_sbxv(idx_t start_sbtv, idx_t start_sbwv, idx_t start_sbxv, idx_t start_sbyv, idx_t start_sbzv, idx_t stop_sbwv, idx_t stop_sbxv, idx_t stop_sbyv, idx_t stop_sbzv) {
 idx_t tv = start_sbtv;
 idx_t xv = start_sbxv;
 idx_t yv = start_sbyv;
 idx_t zv = start_sbzv;
 prefetch_cluster_x<level>(tv, xv, yv, zv);
} // prefetch_cluster shim.

 // Prefetches cache line(s) for leading edge of stencil advancing by 1 vector(s) in '+y' direction relative to indices t, x, y, z in a 'x=1 * y=1 * z=4' cluster containing 1 'x=1 * y=1 * z=4' vector(s).
 // Indices must be normalized, i.e., already divided by VLEN_*.
 template<int level> inline void prefetch_cluster_y(idx_t tv, idx_t xv, idx_t yv, idx_t zv) {

 // Aligned data at t, x, y, z.
 _context->data->prefetchVecNorm<level>(tv, xv, yv, zv, __LINE__);

 // Aligned k_0 at t, x, y, z.
 _context->k_0->prefetchVecNorm<level>(tv, xv, yv, zv, __LINE__);

 // Aligned k_1 at t, x, y, z.
 _context->k_1->prefetchVecNorm<level>(tv, xv, yv, zv, __LINE__);

 // Aligned k_2 at t, x, y, z.
 _context->k_2->prefetchVecNorm<level>(tv, xv, yv, zv, __LINE__);
} // prefetch_cluster_y.

 // Simple shim function to map sub-block start vars to simple vars (ignoring stop vars).
 template <int level> inline void prefetch_cluster_sbyv(idx_t start_sbtv, idx_t start_sbwv, idx_t start_sbxv, idx_t start_sbyv, idx_t start_sbzv, idx_t stop_sbwv, idx_t stop_sbxv, idx_t stop_sbyv, idx_t stop_sbzv) {
 idx_t tv = start_sbtv;
 idx_t xv = start_sbxv;
 idx_t yv = start_sbyv;
 idx_t zv = start_sbzv;
 prefetch_cluster_y<level>(tv, xv, yv, zv);
} // prefetch_cluster shim.

 // Prefetches cache line(s) for leading edge of stencil advancing by 1 vector(s) in '+z' direction relative to indices t, x, y, z in a 'x=1 * y=1 * z=4' cluster containing 1 'x=1 * y=1 * z=4' vector(s).
 // Indices must be normalized, i.e., already divided by VLEN_*.
 template<int level> inline void prefetch_cluster_z(idx_t tv, idx_t xv, idx_t yv, idx_t zv) {

 // Aligned data at t, x, y, z.
 _context->data->prefetchVecNorm<level>(tv, xv, yv, zv, __LINE__);

 // Aligned k_0 at t, x, y, z.
 _context->k_0->prefetchVecNorm<level>(tv, xv, yv, zv, __LINE__);

 // Aligned k_1 at t, x, y, z.
 _context->k_1->prefetchVecNorm<level>(tv, xv, yv, zv, __LINE__);

 // Aligned k_2 at t, x, y, z.
 _context->k_2->prefetchVecNorm<level>(tv, xv, yv, zv, __LINE__);
} // prefetch_cluster_z.

 // Simple shim function to map sub-block start vars to simple vars (ignoring stop vars).
 template <int level> inline void prefetch_cluster_sbzv(idx_t start_sbtv, idx_t start_sbwv, idx_t start_sbxv, idx_t start_sbyv, idx_t start_sbzv, idx_t stop_sbwv, idx_t stop_sbxv, idx_t stop_sbyv, idx_t stop_sbzv) {
 idx_t tv = start_sbtv;
 idx_t xv = start_sbxv;
 idx_t yv = start_sbyv;
 idx_t zv = start_sbzv;
 prefetch_cluster_z<level>(tv, xv, yv, zv);
} // prefetch_cluster shim.

 // Calculate one sub-block of whole clusters.
 virtual void calc_sub_block_of_clusters(idx_t begin_sbtv, idx_t begin_sbxv, idx_t begin_sbyv, idx_t begin_sbzv, idx_t end_sbtv, idx_t end_sbxv, idx_t end_sbyv, idx_t end_sbzv) {

 // Steps and group sizes are based on cluster lengths.
 const idx_t step_sbtv = CLEN_T;
 const idx_t group_size_sbtv = CLEN_T;
 const idx_t step_sbxv = CLEN_X;
 const idx_t group_size_sbxv = CLEN_X;
 const idx_t step_sbyv = CLEN_Y;
 const idx_t group_size_sbyv = CLEN_Y;
 const idx_t step_sbzv = CLEN_Z;
 const idx_t group_size_sbzv = CLEN_Z;
 const idx_t begin_sbwv = 0; // not used in this stencil.
 const idx_t end_sbwv = 1;
 const idx_t step_sbwv = CLEN_W;
 const idx_t group_size_sbwv = CLEN_W;
 #if !defined(DEBUG) && defined(__INTEL_COMPILER)
 #pragma forceinline recursive
 #endif
 {
  // Include automatically-generated loop code that calls calc_cluster()  and optionally, the prefetch function(s).
  #include "stencil_sub_block_loops.hpp"
 }
} // calc_sub_block_of_clusters
}; // EqGroup_stencil_0.

 ////// Overall stencil-specific context //////
struct StencilContext_ys_RHS_LC_emb_jil_yasksite_Heat2D : public StencilContext_ys_RHS_LC_emb_jil_yasksite_Heat2D_data {

 // Stencil equation-groups.
 EqGroup_stencil_1 eqGroup_stencil_1;
 EqGroup_stencil_2 eqGroup_stencil_2;
 EqGroup_stencil_0 eqGroup_stencil_0;

 // Constructor.
 StencilContext_ys_RHS_LC_emb_jil_yasksite_Heat2D(StencilSettings& settings) : StencilContext_ys_RHS_LC_emb_jil_yasksite_Heat2D_data(settings),
  eqGroup_stencil_1(this),
  eqGroup_stencil_2(this),
  eqGroup_stencil_0(this) {

 // Equation groups.
  eqGroups.push_back(&eqGroup_stencil_1);
  eqGroup_stencil_1.add_dep(yask::certain_dep, &eqGroup_stencil_2);
  eqGroups.push_back(&eqGroup_stencil_2);
  eqGroups.push_back(&eqGroup_stencil_0);
  eqGroup_stencil_0.add_dep(yask::certain_dep, &eqGroup_stencil_1);
  eqGroup_stencil_0.add_dep(yask::certain_dep, &eqGroup_stencil_2);
 } // Ctor.
}; // StencilContext_ys_RHS_LC_emb_jil_yasksite_Heat2D
} // namespace yask.
